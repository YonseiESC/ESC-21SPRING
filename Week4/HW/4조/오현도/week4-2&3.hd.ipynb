{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Gibbs Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "import matplotlib.transforms as transforms\n",
    "\n",
    "def plot_gaussian_from_points(x, y, ax, n_std=3.0, facecolor='none', **kwargs):\n",
    "    \"\"\"\n",
    "    Create a plot of the covariance confidence ellipse of *x* and *y*.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x, y : array-like, shape (n, )\n",
    "        Input data.\n",
    "    ax : matplotlib.axes.Axes\n",
    "        The axes object to draw the ellipse into.\n",
    "    n_std : float\n",
    "        The number of standard deviations to determine the ellipse's radiuses.\n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.patches.Ellipse\n",
    "    Other parameters\n",
    "    ----------------\n",
    "    kwargs : `~matplotlib.patches.Patch` properties\n",
    "    \"\"\"\n",
    "    if len(x) != len(y):\n",
    "        raise ValueError(\"x and y must be the same size\")\n",
    "    if len(x) < 2:\n",
    "        raise ValueError(\"Need more data.\")\n",
    "    cov = np.cov(x, y)\n",
    "    pearson = cov[0, 1]/np.sqrt(cov[0, 0] * cov[1, 1])\n",
    "    # Using a special case to obtain the eigenvalues of this\n",
    "    # two-dimensionl dataset.\n",
    "    ell_radius_x = np.sqrt(1 + pearson)\n",
    "    ell_radius_y = np.sqrt(1 - pearson)\n",
    "    ellipse = Ellipse((0, 0),\n",
    "        width=ell_radius_x * 2,\n",
    "        height=ell_radius_y * 2,\n",
    "        facecolor=facecolor,\n",
    "        **kwargs)\n",
    "\n",
    "    # Calculating the stdandard deviation of x from\n",
    "    # the squareroot of the variance and multiplying\n",
    "    # with the given number of standard deviations.\n",
    "    scale_x = np.sqrt(cov[0, 0]) * n_std\n",
    "    mean_x = np.mean(x)\n",
    "\n",
    "    # calculating the stdandard deviation of y ...\n",
    "    scale_y = np.sqrt(cov[1, 1]) * n_std\n",
    "    mean_y = np.mean(y)\n",
    "\n",
    "    transf = transforms.Affine2D() \\\n",
    "        .rotate_deg(45) \\\n",
    "        .scale(scale_x, scale_y) \\\n",
    "        .translate(mean_x, mean_y)\n",
    "\n",
    "    ellipse.set_transform(transf + ax.transData)\n",
    "    return ax.add_patch(ellipse)\n",
    "\n",
    "def plot_gaussian_from_parameters(mean, cov, ax, n_std=3.0, facecolor='none', **kwargs):\n",
    "    \"\"\"\n",
    "    Create a plot of the covariance confidence ellipse of *x* and *y*.\n",
    "    Parameters\n",
    "    ----------\n",
    "\tmean : array-like, shape (2, )\n",
    "    \tMean vector\n",
    "    cov : array-like, shape (2,2)\n",
    "    \tCovariance matrix\n",
    "    ax : matplotlib.axes.Axes\n",
    "        The axes object to draw the ellipse into.\n",
    "    n_std : float\n",
    "        The number of standard deviations to determine the ellipse's radiuses.\n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.patches.Ellipse\n",
    "    Other parameters\n",
    "    ----------------\n",
    "    kwargs : `~matplotlib.patches.Patch` properties\n",
    "    \"\"\"\n",
    "    if len(mean) != 2:\n",
    "        raise ValueError(\"Mean vector length should be 2.\")\n",
    "    if (cov.shape != (2, 2)):\n",
    "    \traise ValueError(\"Covariance should be a 2x2 matrix.\")\n",
    "    #checking if cov is symmetric pos semidefinite\n",
    "    if(cov[0, 1] != cov[1, 0]):\n",
    "        raise ValueError(\"Covariance should be symmetric.\")\n",
    "    if(cov[0, 0] < 0 or cov[0, 0]*cov[1,1] - cov[0,1]**2 < 0):\n",
    "        raise ValueError(\"Covariance should be positive semidefinite.\")\n",
    "\n",
    "    pearson = cov[0, 1]/np.sqrt(cov[0, 0] * cov[1, 1])\n",
    "    # Using a special case to obtain the eigenvalues of this\n",
    "    # two-dimensionl dataset.\n",
    "    ell_radius_x = np.sqrt(1 + pearson)\n",
    "    ell_radius_y = np.sqrt(1 - pearson)\n",
    "    ellipse = Ellipse((0, 0),\n",
    "        width=ell_radius_x * 2,\n",
    "        height=ell_radius_y * 2,\n",
    "        facecolor=facecolor,\n",
    "        **kwargs)\n",
    "\n",
    "    # Calculating the stdandard deviation of x from\n",
    "    # the squareroot of the variance and multiplying\n",
    "    # with the given number of standard deviations.\n",
    "    scale_x = np.sqrt(cov[0, 0]) * n_std\n",
    "    mean_x = mean[0]\n",
    "\n",
    "    # calculating the stdandard deviation of y ...\n",
    "    scale_y = np.sqrt(cov[1, 1]) * n_std\n",
    "    mean_y = mean[1]\n",
    "\n",
    "    transf = transforms.Affine2D() \\\n",
    "        .rotate_deg(45) \\\n",
    "        .scale(scale_x, scale_y) \\\n",
    "        .translate(mean_x, mean_y)\n",
    "\n",
    "    ellipse.set_transform(transf + ax.transData)\n",
    "    return ax.add_patch(ellipse)\n",
    "\n",
    "\n",
    "# from random import random\n",
    "\n",
    "# x = np.array([random()*5 for i in range(500)])\n",
    "# y = np.array([random()*5 for i in range(500)])\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_axes([0,0,1,1])\n",
    "# ax.scatter(x, y)\n",
    "# print(plot_gaussian_from_points(x, y, ax, n_std=1, edgecolor='red'))\n",
    "# #print(plot_gaussian_from_parameters(np.array([2.5, 2.5]), np.cov(x, y), ax, n_std=1, edgecolor='red'))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import gif\n",
    "# gif 가 잘 안 읽히신다면 아래 코드로 설치해주세요\n",
    "!pip install -U gif --user\n",
    "!pip install \"gif[matplotlib]\" --user \n",
    "import gif\n",
    "from IPython.display import Image\n",
    "from random import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def conditional_sampler(sampling_index, current_x, mean, cov):\n",
    "    conditioned_index = 1 - sampling_index # 두 r.v. 중에 뭘 sampling할지 결정\n",
    "    a = cov[sampling_index, sampling_index] # Sigma00\n",
    "    b = cov[sampling_index, conditioned_index]  # Sigma01\n",
    "    c = cov[conditioned_index, conditioned_index]  # Sigma11\n",
    "    \n",
    "    mu = mean[sampling_index]+(b*current_x[conditioned_index]-mean[conditioned_index])/c\n",
    "    sigma = np.sqrt(a-(b**2)/c)\n",
    "    new_x = np.copy(current_x)\n",
    "    new_x[sampling_index] = np.random.randn()*sigma + mu\n",
    "    # [x_0, x_1] 꼴의 1x2 np.array를 return\n",
    "    return new_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def gibbs_sampler(initial_point, num_samples, mean, cov, create_gif=True):\n",
    "    \"\"\"\n",
    "    [input 형태]\n",
    "    initial_point = [x_0, x_1] = [-9.0, -9.0]\n",
    "    num_samples = 100\n",
    "    mean = np.array([0, 0])\n",
    "    cov = np.array([[10, 3], \n",
    "                    [3, 5]])\n",
    "    \"\"\"\n",
    "    frames = []  # for GIF\n",
    "    point = np.array(initial_point)\n",
    "    samples = np.empty([num_samples+1, 2])  # sampled points\n",
    "    samples[0] = point\n",
    "    tmp_points = np.empty([num_samples, 2]) # inbetween points (중간저장소)\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        # 요 for loop이 gibbs sampler 핵심\n",
    "        # point = [x_0, x_1]\n",
    "        \n",
    "        # Sample from p(x_0|x_1)\n",
    "        point = conditional_sampler(0, point, mean, cov)\n",
    "        tmp_points[i] = point\n",
    "        if(create_gif):\n",
    "            frames.append(plot_samples(samples, i+1, tmp_points, i+1, title=\"Num Samples: \" + str(i)))\n",
    "            \n",
    "        # Sample from p(x_1|x_0)\n",
    "        point = conditional_sampler(1, point, mean, cov)\n",
    "        samples[i+1] = point\n",
    "        if(create_gif):\n",
    "            frames.append(plot_samples(samples, i+2, tmp_points, i+1, title=\"Num Samples: \" + str(i+1)))\n",
    "            \n",
    "    if(create_gif):\n",
    "        return samples, tmp_points, frames\n",
    "    else:\n",
    "        return samples, tmp_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@gif.frame\n",
    "def plot_samples(samples, num_samples, tmp_points, num_tmp, title=\"Gibbs Sampling\", xlims=(-11, 11), ylims=(-11, 11)):\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.gca()\n",
    "    \n",
    "    # Plot the true distribution\n",
    "    plot_gaussian_from_parameters(mean, cov, ax, n_std=2, edgecolor='g', alpha=0.5, label=\"True Distribution\")\n",
    "    \n",
    "    # Plot sampled points\n",
    "    ax.scatter(samples[:num_samples, 0], samples[:num_samples, 1], c='b', s=10, label=\"Sampled Points\")\n",
    "    ax.scatter(samples[0, 0], samples[0, 1], marker='*', c='g', s=60, label=\"Initial Point\")\n",
    "    \n",
    "    # Plot samples from conditional distribution\n",
    "    ax.scatter(tmp_points[:num_tmp, 0], tmp_points[:num_tmp, 1], c='r', alpha=0.4, s=5, label=\"Temporary Points\")\n",
    "    \n",
    "    # Keeping the axes scales same for good GIFS\n",
    "    ax.set_xlim(xlims)\n",
    "    ax.set_ylim(ylims)\n",
    "    \n",
    "    # Plot lines\n",
    "    if(num_tmp > 0):\n",
    "        ax.plot([samples[num_samples-1, 0], tmp_points[num_tmp-1, 0]], \n",
    "                [samples[num_samples-1, 1], tmp_points[num_tmp-1, 1]], c='k', alpha=0.25)\n",
    "        # Plot estimated Gaussian, ignoring the starting point\n",
    "        if(num_samples > 2):\n",
    "            plot_gaussian_from_points(samples[1:num_samples, 0], samples[1:num_samples, 1], \n",
    "                                      ax, n_std=2, edgecolor='b', alpha=0.5, label=\"Estimated Distribution\")\n",
    "    \n",
    "    ax.legend(loc='upper left')\n",
    "    ax.set_title(title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean = np.array([0, 0])\n",
    "cov = np.array([[10, 3], \n",
    "                [3, 5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot true distribution\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.gca()\n",
    "plot_gaussian_from_parameters(mean, cov, ax, n_std=2, edgecolor='g', label=\"True Distribution\")\n",
    "ax.scatter(mean[0], mean[1], c='g')\n",
    "ax.set_xlim((-11, 11))\n",
    "ax.set_ylim((-11, 11))\n",
    "ax.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "initial_point = [-9.0, -9.0]\n",
    "num_samples = 500\n",
    "samples, tmp_points, frames = gibbs_sampler(initial_point, num_samples, mean, cov, create_gif=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the GIF\n",
    "# 초당 한 번 update 할 수 있게 느으으으린 움짤임\n",
    "gif.save(frames, \"gibbs500.gif\", duration=500)\n",
    "Image(filename=\"gibbs500.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. NA imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diabetes = pd.read_csv('diabetes.csv')\n",
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diabetes.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Mark invalid zero values as NaN (null)\n",
    "temp_cols = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']  \n",
    "diabetes[temp_cols] = diabetes[temp_cols].replace(0, np.nan)\n",
    "print(diabetes.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize the number of missing values as a matrix\n",
    "fig = msno.matrix(diabetes, inline=False, figsize=(13.33,7.5))\n",
    "\n",
    "# Add labels\n",
    "plt.xlabel('Variables', size=24, labelpad=16)\n",
    "plt.ylabel('Total Observations', size=24, labelpad=16)\n",
    "plt.tick_params(axis='both', labelsize=16, length=8)\n",
    "\n",
    "plt.show;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize the number of missing values as a heatmap\n",
    "fig = msno.heatmap(diabetes, inline=False, figsize=(12,8))\n",
    "\n",
    "# Add labels\n",
    "plt.xlabel('Variables with Missing Values', size=20, labelpad=24)\n",
    "plt.ylabel('Variables with Missing Values', size=20, labelpad=24)\n",
    "plt.tick_params(axis='both', labelsize=12, length=6)\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = diabetes[['Glucose', 'BloodPressure', 'SkinThickness', 'BMI']]\n",
    "\n",
    "g = sns.pairplot(data, diag_kind=\"kde\")\n",
    "g.map_lower(sns.kdeplot, levels=4, color=\".2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling Scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n = data.shape[0]       # data 수\n",
    "p = data.shape[1]       # column 수\n",
    "\n",
    "S = 100                 # number of iteration (몇 번 update 할건지)\n",
    "\n",
    "# 자주 쓰는 함수\n",
    "inv = np.linalg.inv     # 역행렬 구하기\n",
    "t = np.transpose        # transpose\n",
    "\n",
    "# priors\n",
    "## prior for mu ~ N(  ,   )\n",
    "# mean vector mu_0\n",
    "mu0 = data.mean().to_numpy()    # column mean\n",
    "\n",
    "# covariance matrix Lambda_0 : 공분산 행렬 만들기\n",
    "sd0 = mu0 / 2                   # 왜 이렇게 initialize하는지 모르겠지만 암튼 prior란 원래 나름의 믿음에 따라 주는거니까..\n",
    "# 아마 actual dataset의 dispersion을 고려하거나 해서 그런게 아닐까..?\n",
    "L0 = np.ones((p,p))*0.1         # Lambda0 in prior    \n",
    "di = np.diag_indices(p)         # diagonal index indicator\n",
    "L0[di] = 1                      # 일단 분산을 1로 init\n",
    "L0 = L0 * np.outer(sd0, sd0)    # off-diagonal terms\n",
    "\n",
    "## prior for Sigma ~ Ing-Wishart(   ,   )\n",
    "nu0 = p + 2                     # first param\n",
    "S0 = (nu0-p-1)*L0\n",
    "\n",
    "# misc\n",
    "Sigma = S0                      # mu의 full conditional posterior를 초기화하는데 필요함\n",
    "fill_data = data.copy()         # imputate할 dataset copy 만들기\n",
    "\n",
    "O = data.isna().to_numpy()*1    # indicator variable (결측치 있으면 1, 결측치 없으면 0)\n",
    "\n",
    "# Naive Imputation\n",
    "for col in fill_data.columns:\n",
    "    # 일단 mean imputation\n",
    "    # 아마 계산 시 nan 있어서 생기는 error를 방지하기 위해서 나이브하게 뭐라도 채워놓고 simulation을 돌린것같음.\n",
    "    fill_data[col].fillna(fill_data[col].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Imputation  \n",
    "\n",
    "Pros:\n",
    "\n",
    "Prevent data loss which results in deletion of rows or columns\n",
    "Works well with a small dataset and easy to implement.\n",
    "\n",
    "\n",
    "Cons:\n",
    "\n",
    "Works only with numerical continuous variables.\n",
    "Can cause data leakage\n",
    "Does not factor the 'covariance between features.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g_naive = sns.pairplot(fill_data, diag_kind=\"kde\")\n",
    "g_naive.map_lower(sns.kdeplot, levels=4, color=\".2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gibbs Sampler Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for s in range(S):\n",
    "    # update mu\n",
    "    ybar = fill_data.mean().to_numpy()\n",
    "    Ln = inv(inv(L0)+inv(Sigma)*n)        # Lambda_n\n",
    "    mun = np.matmul(Ln, np.matmul(inv(L0),mu0)+np.matmul(n*inv(Sigma),ybar))       # mu_n\n",
    "    ## sample mu from full conditional probability given Sigma & y ##\n",
    "    Mu = stats.multivariate_normal.rvs(mun,Ln,1)      \n",
    "\n",
    "    # update Sigma\n",
    "    S_mu = np.matmul(t(fill_data-Mu).to_numpy(),(fill_data-Mu).to_numpy())\n",
    "    Sn = S0+S_mu\n",
    "    ## sample Sigma from full conditional probability given mu & y ##\n",
    "    Sigma = inv(stats.wishart.rvs(nu0+n,inv(Sn),1)\n",
    "\n",
    "    # update missing data\n",
    "    for i in range(n):\n",
    "\n",
    "        # row별로 돌아가면서 1x4 array에 대해서 imputation\n",
    "        # [T, F, F, T] 등의 형태로 indexing\n",
    "        a = O[i,]==0        # i번째 row에 결측치 없는 위치\n",
    "        b = O[i,]==1        # i번째 row에 결측치 있는 위치\n",
    "\n",
    "        if sum(b)!=0:       # 결측치가 하나라도 있으면 imputation 진행! (결측치 하나도 없으면 sum(b)==0 loop 벗어남)\n",
    "            # iSa, beta_j에 관한 설명은 좀 어려워서 스킵\n",
    "            # 궁금하면 FCB p118 (7.10), (7.11) equation 설명 참고\n",
    "            iSa = inv(Sigma[np.outer(a,a)].reshape(sum(a),sum(a)))\n",
    "            beta_j = np.matmul(Sigma[np.outer(b,a)].reshape(sum(b),sum(a)), iSa)\n",
    "\n",
    "            # Covariance Matrix for MVN distribution\n",
    "            Sigma_j = Sigma[np.outer(b,b)].reshape(sum(b),sum(b)) - np.linalg.multi_dot([Sigma[np.outer(b,a)].reshape(sum(b),sum(a)), iSa, Sigma[np.outer(a,b)].reshape(sum(a),sum(b))])\n",
    "            # Mean Vector for MVN distribution\n",
    "            mu_j = Mu[b] + np.matmul(beta_j, t(fill_data.iloc[i, a])-Mu[a])\n",
    "\n",
    "            # MVN 에서 결측치 있는 위치 (b)만 sampling한 값으로 채우기!\n",
    "            fill_data.iloc[i,b] = stats.multivariate_normal.rvs(mu_j, Sigma_j, 1)\n",
    "\n",
    "    if s%10==0:\n",
    "        print(s,\"/\",S)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # debug statement (각각이 어떤 shape, dimension인지 확인하고 싶으면 주석 해제해서 실행해보기)\n",
    "# ybar = fill_data.mean().to_numpy()\n",
    "# ybar\n",
    "# Ln = inv(inv(L0) + inv(Sigma)*n)\n",
    "# print(Ln.shape)\n",
    "# mun = np.matmul(Ln, np.matmul(inv(L0), mu0) + np.matmul(n*inv(Sigma), ybar))\n",
    "# print(mun.shape)\n",
    "# Mu = stats.multivariate_normal.rvs(mun, Ln, 1)\n",
    "# print(Mu)\n",
    "\n",
    "# Sn = S0 + np.matmul(t(fill_data-Mu).to_numpy(), (fill_data-Mu).to_numpy())\n",
    "# print(Sn)\n",
    "# Sigma = inv(stats.wishart.rvs(nu0+n, inv(Sn), 1))\n",
    "# print(Sigma)\n",
    "\n",
    "# a = O[33,]==0\n",
    "# print(a)\n",
    "# b = O[33,]==1\n",
    "# print(b)\n",
    "# iSa = inv(Sigma[np.outer(a,a)].reshape(sum(a),sum(a)))\n",
    "# print(iSa)  \n",
    "# beta_j = np.matmul(Sigma[np.outer(b,a)].reshape(sum(b),sum(a)), iSa)\n",
    "# print(beta_j)\n",
    "# Sigma_j = Sigma[np.outer(b,b)].reshape(sum(b),sum(b)) - np.linalg.multi_dot([Sigma[np.outer(b,a)].reshape(sum(b),sum(a)), iSa, Sigma[np.outer(a,b)].reshape(sum(a),sum(b))])\n",
    "# print(Sigma_j)\n",
    "# mu_j = Mu[b] + np.matmul(beta_j, t(fill_data.iloc[3, a])-Mu[a])\n",
    "# print(mu_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fill_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Visualize the number of missing values as a matrix\n",
    "fig = msno.matrix(fill_data, inline=False, figsize=(13.33,7.5))\n",
    "\n",
    "# Add labels\n",
    "plt.xlabel('Variables', size=24, labelpad=16)\n",
    "plt.ylabel('Total Observations', size=24, labelpad=16)\n",
    "plt.tick_params(axis='both', labelsize=16, length=8)\n",
    "\n",
    "plt.show;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g_filled = sns.pairplot(fill_data, diag_kind=\"kde\")\n",
    "g_filled.map_lower(sns.kdeplot, levels=4, color=\".2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원 데이터의 분포 보존 확인!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appendix\n",
    "당연히 이런 수고스러움을 거칠필요 없이 석박사들이 만들어놓은 패키지에 더 좋은 Imputator들이 있다!\n",
    "간단히 소개하자면\n",
    "\n",
    "pandas : 위에서 naive하게 column mean으로 채우는 건 pandas의 .fillna를 이용해서 채울 수 있다. 이 외에도 데이터에 시간적인 순서가 있다면 ffill 등을 이용해서 직전 값, 직후의 값으로 채우는 방법도 있다.\n",
    "sklearn : SimpleImputer가 평균값으로 채우는 방법, IterativeImputer가 MICE를 이용해서 채우는 방법이다.\n",
    "MICE (Multivariate Imputation by Chained Equations) : 본 노트북과 같은 방법을 mice라고 부른다. 사실 대부분 패키지의 mice가 bayesian imputation, gibbs sampler의 아이디어를 차용한 것은 맞으나 대부분의 mice implementaion은 frequentist 관점에서 주어진 값들에 대해 regression을 활용하여 결측치를 예측하는 방법으로 구현되어 있는듯하다!\n",
    "물론 어떨 때는 걍 drop하는 게 더 좋을 수도 있다!\n",
    "각각 사용예시는 medium이나 위의 reference에 많으니 궁금한 사람들은 한 번 해보세요!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
